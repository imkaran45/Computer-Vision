{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6382e18f",
   "metadata": {},
   "source": [
    "<h1> Objective:- Assessment Task 4.1P: Object detection </h1>\n",
    "\n",
    "<div style=\"text-align: right\"> Done by: <b>Karan Murjani </b> </div>\n",
    "<div style=\"text-align: right\"> StudentId: <b> 2210470832 </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc1c6c",
   "metadata": {},
   "source": [
    "### 1. Bag-of-Words (BoW) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc64f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feaa323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining class\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self, name, img_filenames, num_words):\n",
    "        self.name = name #name of your dictionary\n",
    "        self.img_filenames = img_filenames #list of image filenames\n",
    "        self.num_words = num_words #the number of words\n",
    "\n",
    "        self.training_data = [] #this is the training data required by the K-Means algorithm\n",
    "        self.words = [] #list of words, which are the centroids of clusters\n",
    "\n",
    "    def learn(self):\n",
    "        sift = cv.SIFT_create()\n",
    "        num_keypoints = [] #this is used to store the number of keypoints in each image\n",
    "\n",
    "     #load training images and compute SIFT descriptors\n",
    "        for filename in self.img_filenames:\n",
    "            img = cv.imread(filename)\n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            list_des = sift.detectAndCompute(img_gray, None)[1]\n",
    "            if list_des is None:\n",
    "                num_keypoints.append(0)\n",
    "            else:\n",
    "                num_keypoints.append(len(list_des))\n",
    "                for des in list_des:\n",
    "                    self.training_data.append(des)\n",
    "\n",
    "        #cluster SIFT descriptors using K-means algorithm\n",
    "        kmeans = KMeans(self.num_words)\n",
    "        kmeans.fit(self.training_data)\n",
    "        self.words = kmeans.cluster_centers_\n",
    "\n",
    "        #create word histograms for training images\n",
    "        training_word_histograms = [] #list of word histograms of all training images\n",
    "        index = 0\n",
    "        for i in range(0, len(self.img_filenames)):\n",
    "            #for each file, create a histogram\n",
    "            histogram = np.zeros(self.num_words, np.float32)\n",
    "            #if some keypoints exist\n",
    "            if num_keypoints[i] > 0:\n",
    "                for j in range(0, num_keypoints[i]):\n",
    "                    histogram[kmeans.labels_[j + index]] += 1\n",
    "                index += num_keypoints[i]\n",
    "                histogram /= num_keypoints[i]\n",
    "                training_word_histograms.append(histogram)\n",
    "\n",
    "        return training_word_histograms\n",
    "\n",
    "    def create_word_histograms(self, img_filenames):\n",
    "        sift = cv.SIFT_create()\n",
    "        histograms = []\n",
    "\n",
    "        for filename in img_filenames:\n",
    "            img = cv.imread(filename)\n",
    "            img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            descriptors = sift.detectAndCompute(img_gray, None)[1]\n",
    "\n",
    "            histogram = np.zeros(self.num_words, np.float32) #word histogram for the input image\n",
    "\n",
    "            if descriptors is not None:\n",
    "                for des in descriptors:\n",
    "                #find the best matching word\n",
    "                    min_distance = 1111111 #this can be any large number\n",
    "                    matching_word_ID = -1 #initial matching_word_ID=-1 means no matching\n",
    "\n",
    "                    for i in range(0, self.num_words): #search for the best matching word\n",
    "                        distance = np.linalg.norm(des - self.words[i])\n",
    "                        if distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            matching_word_ID = i\n",
    "\n",
    "                    histogram[matching_word_ID] += 1\n",
    "\n",
    "                histogram /= len(descriptors) #normalise histogram to frequencies\n",
    "\n",
    "            histograms.append(histogram)\n",
    "\n",
    "        return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c392f85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FoodImages/Train/Cakes/cake20.jpg', 'FoodImages/Train/Cakes/cake21.jpg', 'FoodImages/Train/Cakes/cake23.jpg', 'FoodImages/Train/Cakes/cake22.jpg', 'FoodImages/Train/Cakes/cake26.jpg', 'FoodImages/Train/Cakes/cake27.jpg', 'FoodImages/Train/Cakes/cake9.jpg', 'FoodImages/Train/Cakes/cake25.jpg', 'FoodImages/Train/Cakes/cake19.jpg', 'FoodImages/Train/Cakes/cake18.jpg', 'FoodImages/Train/Cakes/cake30.jpg', 'FoodImages/Train/Cakes/cake24.jpg', 'FoodImages/Train/Cakes/cake8.jpg', 'FoodImages/Train/Cakes/cake5.jpg', 'FoodImages/Train/Cakes/cake29.jpg', 'FoodImages/Train/Cakes/cake15.jpg', 'FoodImages/Train/Cakes/cake14.jpg', 'FoodImages/Train/Cakes/cake28.jpg', 'FoodImages/Train/Cakes/cake4.jpg', 'FoodImages/Train/Cakes/cake6.jpg', 'FoodImages/Train/Cakes/cake16.jpg', 'FoodImages/Train/Cakes/cake17.jpg', 'FoodImages/Train/Cakes/cake7.jpg', 'FoodImages/Train/Cakes/cake13.jpg', 'FoodImages/Train/Cakes/cake3.png', 'FoodImages/Train/Cakes/cake2.png', 'FoodImages/Train/Cakes/cake12.jpg', 'FoodImages/Train/Cakes/cake10.jpg', 'FoodImages/Train/Cakes/cake1.png', 'FoodImages/Train/Cakes/cake11.jpg', 'FoodImages/Train/Pasta/pasta14.jpg', 'FoodImages/Train/Pasta/pasta28.png', 'FoodImages/Train/Pasta/pasta29.jpg', 'FoodImages/Train/Pasta/pasta15.jpg', 'FoodImages/Train/Pasta/pasta17.jpg', 'FoodImages/Train/Pasta/pasta16.jpg', 'FoodImages/Train/Pasta/pasta12.jpg', 'FoodImages/Train/Pasta/pasta13.jpg', 'FoodImages/Train/Pasta/pasta11.jpg', 'FoodImages/Train/Pasta/pasta10.jpg', 'FoodImages/Train/Pasta/pasta3.jpg', 'FoodImages/Train/Pasta/pasta2.jpg', 'FoodImages/Train/Pasta/pasta1.jpg', 'FoodImages/Train/Pasta/pasta5.jpg', 'FoodImages/Train/Pasta/pasta4.jpg', 'FoodImages/Train/Pasta/pasta6.jpg', 'FoodImages/Train/Pasta/pasta7.jpg', 'FoodImages/Train/Pasta/pasta9.jpg', 'FoodImages/Train/Pasta/pasta8.jpg', 'FoodImages/Train/Pasta/pasta21.png', 'FoodImages/Train/Pasta/pasta20.jpg', 'FoodImages/Train/Pasta/pasta22.png', 'FoodImages/Train/Pasta/pasta23.png', 'FoodImages/Train/Pasta/pasta27.png', 'FoodImages/Train/Pasta/pasta26.png', 'FoodImages/Train/Pasta/pasta18.jpg', 'FoodImages/Train/Pasta/pasta30.jpg', 'FoodImages/Train/Pasta/pasta24.png', 'FoodImages/Train/Pasta/pasta25.png', 'FoodImages/Train/Pasta/pasta19.jpg', 'FoodImages/Train/Pizza/pizza6.jpg', 'FoodImages/Train/Pizza/pizza21.jpg', 'FoodImages/Train/Pizza/pizza20.jpg', 'FoodImages/Train/Pizza/pizza7.jpg', 'FoodImages/Train/Pizza/pizza22.jpg', 'FoodImages/Train/Pizza/pizza5.jpg', 'FoodImages/Train/Pizza/pizza4.jpg', 'FoodImages/Train/Pizza/pizza23.jpg', 'FoodImages/Train/Pizza/pizza27.jpg', 'FoodImages/Train/Pizza/pizza26.jpg', 'FoodImages/Train/Pizza/pizza1.png', 'FoodImages/Train/Pizza/pizza18.jpg', 'FoodImages/Train/Pizza/pizza3.jpg', 'FoodImages/Train/Pizza/pizza30.jpg', 'FoodImages/Train/Pizza/pizza24.jpg', 'FoodImages/Train/Pizza/pizza25.jpg', 'FoodImages/Train/Pizza/pizza2.jpg', 'FoodImages/Train/Pizza/pizza19.jpg', 'FoodImages/Train/Pizza/pizza14.jpg', 'FoodImages/Train/Pizza/pizza28.jpg', 'FoodImages/Train/Pizza/pizza29.jpg', 'FoodImages/Train/Pizza/pizza15.jpg', 'FoodImages/Train/Pizza/pizza17.jpg', 'FoodImages/Train/Pizza/pizza16.jpg', 'FoodImages/Train/Pizza/pizza9.jpg', 'FoodImages/Train/Pizza/pizza12.jpg', 'FoodImages/Train/Pizza/pizza13.jpg', 'FoodImages/Train/Pizza/pizza8.jpg', 'FoodImages/Train/Pizza/pizza11.jpg', 'FoodImages/Train/Pizza/pizza10.jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "#Preparing training data\n",
    "foods = ['Cakes', 'Pasta', 'Pizza']\n",
    "path = 'FoodImages/'\n",
    "training_file_names = []\n",
    "training_food_labels = []\n",
    "\n",
    "for i in range(0, len(foods)):\n",
    "    sub_path = path + 'Train/' + foods[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i\n",
    "    training_file_names += sub_file_names\n",
    "    training_food_labels += sub_food_labels\n",
    "\n",
    "print(training_file_names)\n",
    "print(training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93df31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50\n",
    "dictionary_name = 'food'\n",
    "dictionary = Dictionary(dictionary_name, training_file_names, num_words) #Creating an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab6dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling function for an object\n",
    "training_word_histograms = dictionary.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f29f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dictionary\n",
    "with open('food_dictionary.dic', 'wb') as f: #'wb' is for binary write\n",
    "    pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07875463",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('food_dictionary.dic', 'rb') as f: #'rb' is for binary read\n",
    "    dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de462bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0ad0ea7",
   "metadata": {},
   "source": [
    "### 2) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6584b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nearest_neighbours = 5 #number of neighbours\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = num_nearest_neighbours)\n",
    "knn.fit(training_word_histograms, training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f552b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a2a1022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food label:  [1]\n"
     ]
    }
   ],
   "source": [
    "#Prediction of one image\n",
    "test_file_name = ['FoodImages/Test/Pasta/pasta35.jpg']\n",
    "word_histogram_img = dictionary.create_word_histograms(test_file_name)\n",
    "predicted_food_label = knn.predict(word_histogram_img)\n",
    "print('Food label: ', predicted_food_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81459ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FoodImages/Test/Cakes/cake43.jpg', 'FoodImages/Test/Cakes/cake57.jpg', 'FoodImages/Test/Cakes/cake56.jpg', 'FoodImages/Test/Cakes/cake42.jpg', 'FoodImages/Test/Cakes/cake54.jpg', 'FoodImages/Test/Cakes/cake40.jpg', 'FoodImages/Test/Cakes/cake41.jpg', 'FoodImages/Test/Cakes/cake55.jpg', 'FoodImages/Test/Cakes/cake51.jpg', 'FoodImages/Test/Cakes/cake45.jpg', 'FoodImages/Test/Cakes/cake44.jpg', 'FoodImages/Test/Cakes/cake50.jpg', 'FoodImages/Test/Cakes/cake46.jpg', 'FoodImages/Test/Cakes/cake52.jpg', 'FoodImages/Test/Cakes/cake53.jpg', 'FoodImages/Test/Cakes/cake47.jpg', 'FoodImages/Test/Cakes/cake34.jpg', 'FoodImages/Test/Cakes/cake35.jpg', 'FoodImages/Test/Cakes/cake37.jpg', 'FoodImages/Test/Cakes/cake36.jpg', 'FoodImages/Test/Cakes/cake32.jpg', 'FoodImages/Test/Cakes/cake33.jpg', 'FoodImages/Test/Cakes/cake31.jpg', 'FoodImages/Test/Cakes/cake38.jpg', 'FoodImages/Test/Cakes/cake39.jpg', 'FoodImages/Test/Cakes/cake49.jpg', 'FoodImages/Test/Cakes/cake60.jpg', 'FoodImages/Test/Cakes/cake48.jpg', 'FoodImages/Test/Cakes/cake58.jpg', 'FoodImages/Test/Cakes/cake59.jpg', 'FoodImages/Test/Pasta/pasta39.jpg', 'FoodImages/Test/Pasta/pasta38.jpg', 'FoodImages/Test/Pasta/pasta60.jpg', 'FoodImages/Test/Pasta/pasta48.jpg', 'FoodImages/Test/Pasta/pasta49.jpg', 'FoodImages/Test/Pasta/pasta59.jpg', 'FoodImages/Test/Pasta/pasta58.jpg', 'FoodImages/Test/Pasta/pasta42.jpg', 'FoodImages/Test/Pasta/pasta56.jpg', 'FoodImages/Test/Pasta/pasta57.jpg', 'FoodImages/Test/Pasta/pasta43.jpg', 'FoodImages/Test/Pasta/pasta55.jpg', 'FoodImages/Test/Pasta/pasta41.jpg', 'FoodImages/Test/Pasta/pasta40.jpg', 'FoodImages/Test/Pasta/pasta54.jpg', 'FoodImages/Test/Pasta/pasta50.jpg', 'FoodImages/Test/Pasta/pasta44.jpg', 'FoodImages/Test/Pasta/pasta45.jpg', 'FoodImages/Test/Pasta/pasta51.jpg', 'FoodImages/Test/Pasta/pasta47.jpg', 'FoodImages/Test/Pasta/pasta53.jpg', 'FoodImages/Test/Pasta/pasta52.jpg', 'FoodImages/Test/Pasta/pasta46.jpg', 'FoodImages/Test/Pasta/pasta35.jpg', 'FoodImages/Test/Pasta/pasta34.jpg', 'FoodImages/Test/Pasta/pasta36.jpg', 'FoodImages/Test/Pasta/pasta37.jpg', 'FoodImages/Test/Pasta/pasta33.jpg', 'FoodImages/Test/Pasta/pasta32.jpg', 'FoodImages/Test/Pasta/pasta31.jpg', 'FoodImages/Test/Pizza/pizza56.jpg', 'FoodImages/Test/Pizza/pizza42.jpg', 'FoodImages/Test/Pizza/pizza43.jpg', 'FoodImages/Test/Pizza/pizza57.png', 'FoodImages/Test/Pizza/pizza41.jpg', 'FoodImages/Test/Pizza/pizza55.jpg', 'FoodImages/Test/Pizza/pizza54.jpg', 'FoodImages/Test/Pizza/pizza40.jpg', 'FoodImages/Test/Pizza/pizza44.jpg', 'FoodImages/Test/Pizza/pizza50.jpg', 'FoodImages/Test/Pizza/pizza51.jpg', 'FoodImages/Test/Pizza/pizza45.jpg', 'FoodImages/Test/Pizza/pizza53.jpg', 'FoodImages/Test/Pizza/pizza47.jpg', 'FoodImages/Test/Pizza/pizza46.jpg', 'FoodImages/Test/Pizza/pizza52.jpg', 'FoodImages/Test/Pizza/pizza35.jpg', 'FoodImages/Test/Pizza/pizza34.jpg', 'FoodImages/Test/Pizza/pizza36.jpg', 'FoodImages/Test/Pizza/pizza37.jpg', 'FoodImages/Test/Pizza/pizza33.jpg', 'FoodImages/Test/Pizza/pizza32.jpg', 'FoodImages/Test/Pizza/pizza31.jpg', 'FoodImages/Test/Pizza/pizza39.jpg', 'FoodImages/Test/Pizza/pizza38.jpg', 'FoodImages/Test/Pizza/pizza60.jpg', 'FoodImages/Test/Pizza/pizza48.jpg', 'FoodImages/Test/Pizza/pizza49.jpg', 'FoodImages/Test/Pizza/pizza59.png', 'FoodImages/Test/Pizza/pizza58.png']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "#Preparing testing data\n",
    "testing_file_names = []\n",
    "testing_food_labels = []\n",
    "\n",
    "for i in range(0, len(foods)):\n",
    "    sub_path = path + 'Test/' + foods[i] + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    \n",
    "    sub_food_labels = [i] * len(sub_file_names) #create a list of N elements, all are i\n",
    "    \n",
    "    testing_file_names += sub_file_names\n",
    "    testing_food_labels += sub_food_labels\n",
    "\n",
    "print(testing_file_names)\n",
    "print(testing_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7efe7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition Accuracy: 74.44444444444444\n"
     ]
    }
   ],
   "source": [
    "#Prediction for entire folder\n",
    "word_histograms = dictionary.create_word_histograms(testing_file_names)\n",
    "predicted_food_labels = knn.predict(word_histograms)\n",
    "\n",
    "#Evaluation\n",
    "num_correct_predictions = np.sum(predicted_food_labels == testing_food_labels)\n",
    "recognition_acc = num_correct_predictions/len(testing_food_labels)\n",
    "print('Recognition Accuracy:', recognition_acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd412c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  4  8]\n",
      " [ 0 26  4]\n",
      " [ 1  6 23]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(testing_food_labels, predicted_food_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0c3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b6a792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbours: 5\n",
      "Recognition Accuracy: 74.44444444444444\n",
      "Confusion matrix:\n",
      "[[18  4  8]\n",
      " [ 0 26  4]\n",
      " [ 1  6 23]]\n",
      "----------------------------------------\n",
      "Neighbours: 10\n",
      "Recognition Accuracy: 71.11111111111111\n",
      "Confusion matrix:\n",
      "[[16  6  8]\n",
      " [ 0 27  3]\n",
      " [ 0  9 21]]\n",
      "----------------------------------------\n",
      "Neighbours: 15\n",
      "Recognition Accuracy: 67.77777777777779\n",
      "Confusion matrix:\n",
      "[[15  6  9]\n",
      " [ 0 26  4]\n",
      " [ 0 10 20]]\n",
      "----------------------------------------\n",
      "Neighbours: 20\n",
      "Recognition Accuracy: 66.66666666666666\n",
      "Confusion matrix:\n",
      "[[13  8  9]\n",
      " [ 0 26  4]\n",
      " [ 0  9 21]]\n",
      "----------------------------------------\n",
      "Neighbours: 25\n",
      "Recognition Accuracy: 65.55555555555556\n",
      "Confusion matrix:\n",
      "[[10 10 10]\n",
      " [ 0 27  3]\n",
      " [ 0  8 22]]\n",
      "----------------------------------------\n",
      "Neighbours: 30\n",
      "Recognition Accuracy: 63.33333333333333\n",
      "Confusion matrix:\n",
      "[[ 9  9 12]\n",
      " [ 0 27  3]\n",
      " [ 0  9 21]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Measuring accuracy of different number of nearest neighbours\n",
    "num_nearest_neighbours = [5, 10,15,20,25,30]\n",
    "\n",
    "for k in num_nearest_neighbours:\n",
    "    #Train a model\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(training_word_histograms, training_food_labels)\n",
    "\n",
    "    #Prediction\n",
    "    predicted_food_labels = knn.predict(word_histograms)\n",
    "\n",
    "    #Evaluation\n",
    "    num_correct_predictions = np.sum(predicted_food_labels == testing_food_labels)\n",
    "    recognition_acc_k = num_correct_predictions/len(testing_food_labels)\n",
    "    print('Neighbours:', k)\n",
    "    print('Recognition Accuracy:', recognition_acc_k * 100)\n",
    "    \n",
    "    #Confusion matrix\n",
    "    cm = confusion_matrix(testing_food_labels, predicted_food_labels)\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c699c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d421b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9cc829c",
   "metadata": {},
   "source": [
    "### 3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b338e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=50, kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train a model with C=50\n",
    "svm_classifier = svm.SVC(C = 50, kernel = 'linear')\n",
    "svm_classifier.fit(training_word_histograms, training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad6845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition Accuracy: 85.55555555555556\n"
     ]
    }
   ],
   "source": [
    "predicted_food_labels = svm_classifier.predict(word_histograms)\n",
    "\n",
    "#Evaluation\n",
    "num_correct_predictions = np.sum(predicted_food_labels == testing_food_labels)\n",
    "recognition_acc = num_correct_predictions/len(testing_food_labels)\n",
    "print('Recognition Accuracy:', recognition_acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60989f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  2  1]\n",
      " [ 0 25  5]\n",
      " [ 1  4 25]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(testing_food_labels, predicted_food_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92836e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10\n",
      "Recognition Accuracy: 81.11111111111111\n",
      "Confusion matrix:\n",
      "[[24  3  3]\n",
      " [ 0 22  8]\n",
      " [ 1  2 27]]\n",
      "----------------------------------------\n",
      "C: 20\n",
      "Recognition Accuracy: 83.33333333333334\n",
      "Confusion matrix:\n",
      "[[26  2  2]\n",
      " [ 0 22  8]\n",
      " [ 1  2 27]]\n",
      "----------------------------------------\n",
      "C: 30\n",
      "Recognition Accuracy: 82.22222222222221\n",
      "Confusion matrix:\n",
      "[[26  2  2]\n",
      " [ 0 23  7]\n",
      " [ 1  4 25]]\n",
      "----------------------------------------\n",
      "C: 40\n",
      "Recognition Accuracy: 84.44444444444444\n",
      "Confusion matrix:\n",
      "[[26  2  2]\n",
      " [ 0 25  5]\n",
      " [ 1  4 25]]\n",
      "----------------------------------------\n",
      "C: 50\n",
      "Recognition Accuracy: 85.55555555555556\n",
      "Confusion matrix:\n",
      "[[27  2  1]\n",
      " [ 0 25  5]\n",
      " [ 1  4 25]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Vary C in the range [10, 20, 30, 40, 50] and measure the corresponding accuracies. What is the best value for C?\n",
    "\n",
    "C = [10,20,30,40,50]\n",
    "\n",
    "for i in C:\n",
    "    #Train a model\n",
    "    svm_classifier = svm.SVC(C = i, kernel='linear')\n",
    "    svm_classifier.fit(training_word_histograms, training_food_labels)\n",
    "\n",
    "    #Prediction\n",
    "    predicted_food_labels = svm_classifier.predict(word_histograms)\n",
    "\n",
    "    #Evaluation\n",
    "    num_correct_predictions = np.sum(predicted_food_labels == testing_food_labels)\n",
    "    recognition_acc_i = num_correct_predictions/len(testing_food_labels)\n",
    "    print('C:', i)\n",
    "    print('Recognition Accuracy:', recognition_acc_i * 100)\n",
    "    \n",
    "    #Confusion matrix\n",
    "    cm = confusion_matrix(testing_food_labels, predicted_food_labels)\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413718a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b66308a",
   "metadata": {},
   "source": [
    "### 4) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69fbb35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=150, random_state=123)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adb_classifier = AdaBoostClassifier(n_estimators = 150, random_state = 123)\n",
    "adb_classifier.fit(training_word_histograms, training_food_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc2be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition Accuracy: 71.11111111111111\n"
     ]
    }
   ],
   "source": [
    "predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "\n",
    "#Evaluation\n",
    "num_correct_predictions = np.sum(predicted_food_labels == testing_food_labels)\n",
    "recognition_acc = num_correct_predictions/len(testing_food_labels)\n",
    "print('Recognition Accuracy:', recognition_acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa027bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  2  9]\n",
      " [ 0 21  9]\n",
      " [ 0  6 24]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "cm = confusion_matrix(testing_food_labels, predicted_food_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c33c2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Estimators: 50\n",
      "Recognition Accuracy: 71.11111111111111\n",
      "Confusion matrix:\n",
      "[[22  0  8]\n",
      " [ 0 20 10]\n",
      " [ 2  6 22]]\n",
      "----------------------------------------\n",
      "N-Estimators: 100\n",
      "Recognition Accuracy: 72.22222222222221\n",
      "Confusion matrix:\n",
      "[[20  1  9]\n",
      " [ 0 21  9]\n",
      " [ 0  6 24]]\n",
      "----------------------------------------\n",
      "N-Estimators: 150\n",
      "Recognition Accuracy: 71.11111111111111\n",
      "Confusion matrix:\n",
      "[[19  2  9]\n",
      " [ 0 21  9]\n",
      " [ 0  6 24]]\n",
      "----------------------------------------\n",
      "N-Estimators: 200\n",
      "Recognition Accuracy: 71.11111111111111\n",
      "Confusion matrix:\n",
      "[[20  2  8]\n",
      " [ 0 22  8]\n",
      " [ 1  7 22]]\n",
      "----------------------------------------\n",
      "N-Estimators: 250\n",
      "Recognition Accuracy: 75.55555555555556\n",
      "Confusion matrix:\n",
      "[[22  3  5]\n",
      " [ 0 24  6]\n",
      " [ 0  8 22]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Vary n_estimators in the range [50, 100, 150, 200, 250] and measure accuracies. What is the best value for n_estimators?\n",
    "\n",
    "n_estimators = [50, 100, 150, 200, 250]\n",
    "\n",
    "for n in n_estimators:\n",
    "    #Train a model\n",
    "    adb_classifier = AdaBoostClassifier(n_estimators = n, random_state = 123)\n",
    "    adb_classifier.fit(training_word_histograms, training_food_labels)\n",
    "\n",
    "    #Prediction\n",
    "    predicted_food_labels = adb_classifier.predict(word_histograms)\n",
    "\n",
    "    #Evaluation\n",
    "    num_correct_predictions = np.sum(predicted_food_labels == testing_food_labels)\n",
    "    recognition_acc_n = num_correct_predictions/len(testing_food_labels)\n",
    "    print('N-Estimators:', n)\n",
    "    print('Recognition Accuracy:', recognition_acc_n * 100)\n",
    "    \n",
    "    #Confusion matrix\n",
    "    cm = confusion_matrix(testing_food_labels, predicted_food_labels)\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)\n",
    "    print('----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
