{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce426283",
   "metadata": {},
   "source": [
    "<h1> Objective:- Assessment Task 9.2C: Speaker recognition using GMMs </h1>\n",
    "\n",
    "<div style=\"text-align: right\"> Done by: <b>Karan Murjani </b> </div>\n",
    "<div style=\"text-align: right\"> StudentId: <b> 221047083 </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77656097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import mediainfo\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c0baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extraction(audio_filename, #.wav filename\n",
    "                    hop_duration, #hop_length in seconds, e.g., 0.015s (i.e., 15ms)\n",
    "                    num_mfcc #number of mfcc features\n",
    "                   ):\n",
    "    speech = AudioSegment.from_wav(audio_filename) #Read audio data from file\n",
    "    samples = speech.get_array_of_samples() #samples x(t)\n",
    "    sampling_rate = speech.frame_rate #sampling rate f\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "    y = np.float32(samples),\n",
    "    sr = sampling_rate,\n",
    "    hop_length = int(sampling_rate * hop_duration),\n",
    "    n_mfcc = num_mfcc)\n",
    "    return mfcc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a6a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningGMM(features, #list of feature vectors, each feature vector is an array\n",
    "                n_components, #the number of components\n",
    "                max_iter #maximum number of iterations\n",
    "               ):\n",
    "    gmm = GaussianMixture(n_components = n_components, max_iter = max_iter)\n",
    "    gmm.fit(features)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67780f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Azmisov', 'Bahoke', 'Beez', 'Anthony', 'Beady', 'Arjuan', 'Bachroxx', 'Asp', 'Bae', 'Ariyan', 'Argail', 'Ara', 'Asladic', 'Asalkeld', 'Bart', 'Artk', 'Arthur', 'Bassel', 'Artem', 'Bareford', 'AppleEater', 'Arvala', 'BelmontGuy', 'Arun', 'B']\n"
     ]
    }
   ],
   "source": [
    "path = 'SpeakerData/'\n",
    "speakers = os.listdir(path + 'Train/')\n",
    "print(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3657effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this list is used to store the MFCC features of all training data of all speakers\n",
    "mfcc_all_speakers = []\n",
    "hop_duration = 0.015 #15ms\n",
    "num_mfcc = 12\n",
    "for s in speakers:\n",
    "    sub_path = path + 'Train/' + s + '/'\n",
    "    sub_file_names = [os.path.join(sub_path, f) for f in os.listdir(sub_path)]\n",
    "    mfcc_one_speaker = np.asarray(())\n",
    "    for fn in sub_file_names:\n",
    "        mfcc_one_file = mfcc_extraction(fn, hop_duration, num_mfcc)\n",
    "        if mfcc_one_speaker.size == 0:\n",
    "            mfcc_one_speaker = mfcc_one_file\n",
    "        else:\n",
    "            mfcc_one_speaker = np.vstack((mfcc_one_speaker, mfcc_one_file))\n",
    "    mfcc_all_speakers.append(mfcc_one_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a08215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(speakers)):\n",
    "    with open('TrainingFeatures/' + speakers[i] + '_mfcc.fea','wb') as f:\n",
    "        pickle.dump(mfcc_all_speakers[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011ad364",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "max_iter = 50\n",
    "gmms = [] #list of GMMs, each is for a speaker\n",
    "for i in range(0, len(speakers)):\n",
    "    gmm = learningGMM(mfcc_all_speakers[i],\n",
    "                      n_components,\n",
    "                      max_iter)\n",
    "    gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983ee650",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(speakers)):\n",
    "    with open('Models/' + speakers[i] + '.gmm', 'wb') as f: #'wb' is for binary write\n",
    "        pickle.dump(gmms[i], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070bdd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmms = []\n",
    "for i in range(len(speakers)):\n",
    "    with open('Models/' + speakers[i] + '.gmm', 'rb') as f: #'wb' is for binary write\n",
    "        gmm = pickle.load(f)\n",
    "        gmms.append(gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83157cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_duration = 0.015 #15ms\n",
    "num_mfcc = 12\n",
    "def speaker_recognition(audio_file_name, gmms):\n",
    "    speaker_id = 0 #you need to calculate this\n",
    "    score = []\n",
    "    for i, gmm in enumerate(gmms):\n",
    "        mfcc_test = mfcc_extraction(audio_file_name, hop_duration, num_mfcc)\n",
    "        score.append((i,gmms[i].score(mfcc_test)))\n",
    "    max_element = max(score, key=lambda x:x[1])\n",
    "    speaker_id = max_element[0]\n",
    "    return speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0885b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ara\n"
     ]
    }
   ],
   "source": [
    "speaker_id = speaker_recognition('SpeakerData/Test/Ara/a0522.wav', gmms)\n",
    "print(speakers[speaker_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f4aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking across entire test file\n",
    "files = glob.glob(\"SpeakerData/Test/*/*\")\n",
    "y_true = []\n",
    "y_pred = []\n",
    "new_item = []\n",
    "\n",
    "for file in files:\n",
    "    true_label = os.path.basename(os.path.dirname(file))\n",
    "    speaker_id = speaker_recognition(file, gmms)\n",
    "    pred_label = speakers[speaker_id]\n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc0c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9485714285714286\n",
      "Confusion Matrix:\n",
      " [[1 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Anthony       1.00      0.14      0.25         7\n",
      "  AppleEater       1.00      1.00      1.00         7\n",
      "         Ara       1.00      1.00      1.00         7\n",
      "      Argail       1.00      1.00      1.00         7\n",
      "      Ariyan       1.00      1.00      1.00         7\n",
      "      Arjuan       1.00      1.00      1.00         7\n",
      "       Artem       1.00      1.00      1.00         7\n",
      "      Arthur       0.47      1.00      0.64         7\n",
      "        Artk       1.00      1.00      1.00         7\n",
      "        Arun       1.00      1.00      1.00         7\n",
      "      Arvala       1.00      1.00      1.00         7\n",
      "    Asalkeld       1.00      1.00      1.00         7\n",
      "     Asladic       1.00      1.00      1.00         7\n",
      "         Asp       1.00      1.00      1.00         7\n",
      "     Azmisov       1.00      1.00      1.00         7\n",
      "           B       1.00      1.00      1.00         7\n",
      "    Bachroxx       1.00      1.00      1.00         7\n",
      "         Bae       1.00      1.00      1.00         7\n",
      "      Bahoke       1.00      0.86      0.92         7\n",
      "    Bareford       1.00      1.00      1.00         7\n",
      "        Bart       1.00      0.71      0.83         7\n",
      "      Bassel       0.88      1.00      0.93         7\n",
      "       Beady       1.00      1.00      1.00         7\n",
      "        Beez       1.00      1.00      1.00         7\n",
      "  BelmontGuy       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.95       175\n",
      "   macro avg       0.97      0.95      0.94       175\n",
      "weighted avg       0.97      0.95      0.94       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Overall Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
